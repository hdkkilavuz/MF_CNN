{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2378514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras import models, utils, layers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "nClass = 2\n",
    "Classes = list()\n",
    "for n in range(nClass):\n",
    "    Classes.append(f\"Class {n}\")\n",
    "print(f\"Class Number : {nClass}\\n{Classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "ablations = ['', '-PVI', '-BOX']\n",
    "fibrosis = ['50PF', '70PF', '71PF']\n",
    "fibnames = ['moderate fibrosis', 'severe fibrosis - case 1', 'severe fibrosis - case 2']\n",
    "abnames = ['', ' - PVI', ' - PVI + BOX']\n",
    "Cases = []\n",
    "for f in fibrosis:\n",
    "    for a in ablations:\n",
    "        Cases.append(f + a)\n",
    "Names = []\n",
    "for f in fibnames:\n",
    "    for a in abnames:\n",
    "        Names.append(f + a)\n",
    "IdCase = 3\n",
    "print(f\"      cases : {Cases}\")\n",
    "print(f\"      names : {Names}\")\n",
    "print(f\"picked case : {Names[IdCase]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f806afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_H = 40\n",
    "N_L = 100\n",
    "Path = \"../Datasets/\"\n",
    "ChoosePoints = True\n",
    "Y_L_all = np.load(Path + \"LF_train-%s.npz\" % Cases[IdCase])[\"output\"]\n",
    "Y_L = Y_L_all[:N_L]\n",
    "Y_H_all = np.load(Path + \"HF_train-%s.npz\" % Cases[IdCase])[\"output\"]\n",
    "Y_H = Y_H_all[:N_H]\n",
    "y_true = np.load(Path + \"ground_truth-%s.npz\" % Cases[IdCase])[\"output\"]\n",
    "TrainPoints = np.genfromtxt(Path + \"train_points.csv\").astype(float)\n",
    "TruePoints = np.genfromtxt(Path + \"ground_truth_points.csv\").astype(float)\n",
    "if ChoosePoints:\n",
    "    X_true = TruePoints[:,:3]\n",
    "    X_L = TrainPoints[:N_L,:3]\n",
    "    X_H = TrainPoints[:N_H,:3]\n",
    "else:\n",
    "    X_true = TruePoints[:,3]\n",
    "    X_L = TrainPoints[:N_L,3]\n",
    "    X_H = TrainPoints[:N_H,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Y_L_all.shape, Y_H_all.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_true.shape, y_true.shape, X_L.shape, Y_L.shape, X_H.shape, Y_H.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SecLH = 1\n",
    "if SecLH == 0:\n",
    "    xTrain, yTrain = X_L, Y_L\n",
    "else:\n",
    "    xTrain, yTrain = X_H, Y_H\n",
    "xTest = X_true\n",
    "yTest = y_true\n",
    "if len(xTrain.shape) == 1:\n",
    "    xTrain = np.expand_dims(xTrain, axis=-1)\n",
    "    xTest = np.expand_dims(xTest, axis=-1)\n",
    "[xTrain.shape, yTrain.shape, xTest.shape, yTest.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data\n",
    "xMin, xMax = xTrain.min(axis=0), xTrain.max(axis=0)\n",
    "xTrain = (xTrain-xMin) / (xMax-xMin)\n",
    "xTest = (xTest-xMin) / (xMax-xMin)\n",
    "[xTrain.min(axis=0), xTrain.max(axis=0), xTest.min(axis=0), xTest.max(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain = utils.to_categorical(yTrain, nClass)\n",
    "YTest = utils.to_categorical(yTest, nClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "[yTrain.shape, YTrain.shape, yTest.shape, YTest.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = np.expand_dims(xTrain, axis=-1)\n",
    "XTest = np.expand_dims(xTest, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "[xTrain.shape, XTrain.shape, xTest.shape, XTest.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a091913",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292486ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyCnnModel():\n",
    "    Layers = [\n",
    "        layers.Input(shape=XTrain.shape[1:]),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='same', activation=\"relu\", name='Conv1'),\n",
    "        layers.Conv1D(filters=32, kernel_size=3, padding='same', activation=\"relu\", name='Conv2'),\n",
    "        layers.Flatten(name='Flatten1'),\n",
    "        layers.Dense(units=32, activation='relu', name='Dense1'),\n",
    "        layers.Dense(units=32, activation='relu', name='Dense2'),\n",
    "        layers.Dense(nClass, activation='softmax', name='Output')\n",
    "    ]\n",
    "    Model = models.Sequential(Layers,name='MyCnnModel')\n",
    "    Model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return Model\n",
    "CnnModel = MyCnnModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CnnModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CnnModel.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = 100\n",
    "Batch = 5\n",
    "Pat = 10\n",
    "CB = callbacks.EarlyStopping(monitor='val_loss', patience=Pat, restore_best_weights=True)\n",
    "History = CnnModel.fit(XTrain, YTrain, epochs=Epoch, batch_size=Batch, validation_data=(XTest, YTest), callbacks=[CB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b704a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, Acc = CnnModel.evaluate(XTrain, YTrain, verbose=0)\n",
    "print(f\"Train Loss     : {Loss}\")\n",
    "print(f\"Train Accuracy : {Acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a077c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, Acc = CnnModel.evaluate(XTest, YTest, verbose=0)\n",
    "print(f\"Test Loss     : {Loss}\")\n",
    "print(f\"Test Accuracy : {Acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d71ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = History.history[\"loss\"]\n",
    "y2 = History.history[\"val_loss\"]\n",
    "x = list(range(1,1+len(y1)))\n",
    "plt.figure(figsize=(10, 5), dpi=100)\n",
    "plt.plot(x, y1, \"bo-\", lw=2, ms=5)\n",
    "plt.plot(x, y2, \"ro-\", lw=2, ms=5)\n",
    "plt.legend([\"Train Loss\", \"Validation Loss\"])\n",
    "plt.title(\"Cross Entropy Loss\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b328675",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = History.history[\"accuracy\"]\n",
    "y2 = History.history[\"val_accuracy\"]\n",
    "x = list(range(1,1+len(y1)))\n",
    "plt.figure(figsize=(10, 5), dpi=100)\n",
    "plt.plot(x, y1, \"bo-\", lw=2, ms=5)\n",
    "plt.plot(x, y2, \"ro-\", lw=2, ms=5)\n",
    "plt.legend([\"Train Accuracy\", \"Validation Accuracy\"])\n",
    "plt.title(\"Classification Accuracy\")\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48de690",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = yTrain.shape[0]\n",
    "YTrainPred = CnnModel.predict(XTrain)\n",
    "yTrainPred = np.argmax(YTrainPred, axis=1)\n",
    "yTrainFound = sum(yTrain==yTrainPred)\n",
    "nTest = yTest.shape[0]\n",
    "yTrainPercent = 100*yTrainFound/nTrain\n",
    "YTestPred = CnnModel.predict(XTest)\n",
    "yTestPred = np.argmax(YTestPred, axis=1)\n",
    "yTestFound = sum(yTest==yTestPred)\n",
    "yTestPercent = 100*yTestFound/nTrain\n",
    "print(f\"Train Accuracy : {yTrainPercent:.6g} % ({yTrainFound} / {nTrain})\")\n",
    "print(f\" Test Accuracy : {yTestPercent:.6g} % ({yTestFound} / {nTest})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConMatTrain = confusion_matrix(yTrain, yTrainPred)\n",
    "ConMatTest = confusion_matrix(yTest, yTestPred)\n",
    "print(\"For Train Data\", ConMatTrain, sep=\"\\n\", end=\"\\n\\n\")\n",
    "print(\"For Test Data\", ConMatTest, sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d6813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4), dpi=100)\n",
    "plt.subplot(1,2,1)\n",
    "heatmap(data=ConMatTrain, cmap='Blues', linewidths=1, linecolor='gray',\n",
    "        fmt='d', annot=True, xticklabels=Classes, yticklabels=Classes)\n",
    "plt.title(\"For Train Data\", fontsize = 10)\n",
    "plt.xlabel(\"Predicted Classes\", fontsize = 10)\n",
    "plt.ylabel(\"True Classes\", fontsize = 10)\n",
    "plt.subplot(1,2,2)\n",
    "heatmap(data=ConMatTest, cmap='Blues', linewidths=1, linecolor='gray',\n",
    "        fmt='d', annot=True, xticklabels=Classes, yticklabels=Classes)\n",
    "plt.title(\"For Test Data\", fontsize = 10)\n",
    "plt.xlabel(\"Predicted Classes\", fontsize = 10)\n",
    "plt.ylabel(\"True Classes\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c5e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('For Train Data')\n",
    "print(classification_report(yTrain, yTrainPred, target_names=Classes, digits=4))\n",
    "print('For Test Data')\n",
    "print(classification_report(yTest, yTestPred, target_names=Classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07720b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
